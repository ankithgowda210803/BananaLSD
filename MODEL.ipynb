{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1203 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train = keras.utils.image_dataset_from_directory(\n",
    "    directory = 'TRAIN/',\n",
    "    label_mode = 'int',\n",
    "    labels = 'inferred' , \n",
    "    image_size = (64,64),\n",
    "    batch_size = 32 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 396 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "validation = keras.utils.image_dataset_from_directory(\n",
    "    directory = 'TEST/',\n",
    "    label_mode = 'int',\n",
    "    labels = 'inferred' , \n",
    "    image_size = (64,64),\n",
    "    batch_size = 32 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Conv2D , BatchNormalization , MaxPool2D , Dense , Dropout , Flatten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddarth DK\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32 , kernel_size = (3,3) , strides = (2,2) , padding = 'same' , input_shape = (64,64,3) ,activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size = (2,2) , strides = (2,2) , padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 64 , kernel_size = (3,3) , strides = (2,2) , padding = 'same'  ,activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size = (2,2) , strides = (2,2) , padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64 , activation = 'relu' ))\n",
    "model.add(Dense(32 , activation = 'relu' ))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(26 , activation = 'softmax' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam' , loss = tf.losses.SparseCategoricalCrossentropy() , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.2777 - loss: 2.5144 - val_accuracy: 0.2500 - val_loss: 5.8457\n",
      "Epoch 2/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6881 - loss: 0.9851 - val_accuracy: 0.2576 - val_loss: 4.1597\n",
      "Epoch 3/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7622 - loss: 0.6931 - val_accuracy: 0.4369 - val_loss: 2.1251\n",
      "Epoch 4/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8324 - loss: 0.4981 - val_accuracy: 0.5682 - val_loss: 1.4551\n",
      "Epoch 5/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8335 - loss: 0.4698 - val_accuracy: 0.6667 - val_loss: 1.2866\n",
      "Epoch 6/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9092 - loss: 0.2645 - val_accuracy: 0.6995 - val_loss: 1.0963\n",
      "Epoch 7/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9137 - loss: 0.2534 - val_accuracy: 0.6591 - val_loss: 1.2518\n",
      "Epoch 8/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8957 - loss: 0.2708 - val_accuracy: 0.7323 - val_loss: 0.9435\n",
      "Epoch 9/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9378 - loss: 0.2079 - val_accuracy: 0.6616 - val_loss: 0.9739\n",
      "Epoch 10/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9396 - loss: 0.1887 - val_accuracy: 0.7045 - val_loss: 0.9738\n",
      "Epoch 11/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9633 - loss: 0.1271 - val_accuracy: 0.7273 - val_loss: 1.0505\n",
      "Epoch 12/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9738 - loss: 0.1001 - val_accuracy: 0.7551 - val_loss: 0.9304\n",
      "Epoch 13/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9728 - loss: 0.0902 - val_accuracy: 0.7475 - val_loss: 0.9668\n",
      "Epoch 14/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9667 - loss: 0.1181 - val_accuracy: 0.7576 - val_loss: 1.1418\n",
      "Epoch 15/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9644 - loss: 0.1234 - val_accuracy: 0.6465 - val_loss: 1.3835\n",
      "Epoch 16/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9730 - loss: 0.0917 - val_accuracy: 0.7071 - val_loss: 1.3659\n",
      "Epoch 17/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9804 - loss: 0.0608 - val_accuracy: 0.7551 - val_loss: 1.2113\n",
      "Epoch 18/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9629 - loss: 0.1234 - val_accuracy: 0.5455 - val_loss: 1.8575\n",
      "Epoch 19/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9605 - loss: 0.1448 - val_accuracy: 0.6338 - val_loss: 1.6621\n",
      "Epoch 20/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9846 - loss: 0.0528 - val_accuracy: 0.7071 - val_loss: 1.5715\n",
      "Epoch 21/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9831 - loss: 0.0515 - val_accuracy: 0.7172 - val_loss: 1.2962\n",
      "Epoch 22/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9792 - loss: 0.0701 - val_accuracy: 0.7348 - val_loss: 1.1943\n",
      "Epoch 23/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9827 - loss: 0.0457 - val_accuracy: 0.7399 - val_loss: 0.9848\n",
      "Epoch 24/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9799 - loss: 0.0520 - val_accuracy: 0.6010 - val_loss: 2.1886\n",
      "Epoch 25/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9879 - loss: 0.0340 - val_accuracy: 0.6944 - val_loss: 1.5289\n",
      "Epoch 26/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9922 - loss: 0.0249 - val_accuracy: 0.7449 - val_loss: 1.3278\n",
      "Epoch 27/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9947 - loss: 0.0208 - val_accuracy: 0.6793 - val_loss: 1.7759\n",
      "Epoch 28/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9908 - loss: 0.0339 - val_accuracy: 0.7146 - val_loss: 1.3232\n",
      "Epoch 29/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9796 - loss: 0.0589 - val_accuracy: 0.5505 - val_loss: 4.3687\n",
      "Epoch 30/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9681 - loss: 0.0820 - val_accuracy: 0.7273 - val_loss: 1.4495\n",
      "Epoch 31/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9842 - loss: 0.0484 - val_accuracy: 0.7475 - val_loss: 1.5620\n",
      "Epoch 32/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9959 - loss: 0.0201 - val_accuracy: 0.7348 - val_loss: 1.5155\n",
      "Epoch 33/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9852 - loss: 0.0561 - val_accuracy: 0.7273 - val_loss: 1.4876\n",
      "Epoch 34/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9903 - loss: 0.0327 - val_accuracy: 0.6894 - val_loss: 1.5858\n",
      "Epoch 35/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9855 - loss: 0.0362 - val_accuracy: 0.7525 - val_loss: 1.5445\n",
      "Epoch 36/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9802 - loss: 0.0660 - val_accuracy: 0.7298 - val_loss: 1.6084\n",
      "Epoch 37/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9942 - loss: 0.0247 - val_accuracy: 0.7576 - val_loss: 1.2624\n",
      "Epoch 38/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9788 - loss: 0.0887 - val_accuracy: 0.6414 - val_loss: 1.9764\n",
      "Epoch 39/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9837 - loss: 0.0546 - val_accuracy: 0.7222 - val_loss: 1.2100\n",
      "Epoch 40/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9896 - loss: 0.0372 - val_accuracy: 0.6364 - val_loss: 2.2465\n",
      "Epoch 41/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9898 - loss: 0.0414 - val_accuracy: 0.6970 - val_loss: 1.6530\n",
      "Epoch 42/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9830 - loss: 0.0568 - val_accuracy: 0.7348 - val_loss: 1.5374\n",
      "Epoch 43/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9913 - loss: 0.0280 - val_accuracy: 0.7222 - val_loss: 1.6314\n",
      "Epoch 44/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9795 - loss: 0.0533 - val_accuracy: 0.7702 - val_loss: 1.1932\n",
      "Epoch 45/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9988 - loss: 0.0092 - val_accuracy: 0.7677 - val_loss: 1.4196\n",
      "Epoch 46/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9969 - loss: 0.0200 - val_accuracy: 0.7626 - val_loss: 1.6048\n",
      "Epoch 47/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9916 - loss: 0.0302 - val_accuracy: 0.7601 - val_loss: 1.5422\n",
      "Epoch 48/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9915 - loss: 0.0326 - val_accuracy: 0.7525 - val_loss: 1.6093\n",
      "Epoch 49/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9862 - loss: 0.0440 - val_accuracy: 0.5657 - val_loss: 2.7068\n",
      "Epoch 50/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9735 - loss: 0.0584 - val_accuracy: 0.6944 - val_loss: 1.9222\n",
      "Epoch 51/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9947 - loss: 0.0226 - val_accuracy: 0.7449 - val_loss: 1.9600\n",
      "Epoch 52/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9962 - loss: 0.0109 - val_accuracy: 0.7576 - val_loss: 1.5971\n",
      "Epoch 53/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9969 - loss: 0.0107 - val_accuracy: 0.7551 - val_loss: 1.7926\n",
      "Epoch 54/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9886 - loss: 0.0207 - val_accuracy: 0.7424 - val_loss: 1.4324\n",
      "Epoch 55/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9986 - loss: 0.0090 - val_accuracy: 0.7677 - val_loss: 1.5963\n",
      "Epoch 56/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9981 - loss: 0.0097 - val_accuracy: 0.7096 - val_loss: 1.9344\n",
      "Epoch 57/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9998 - loss: 0.0063 - val_accuracy: 0.6288 - val_loss: 2.9909\n",
      "Epoch 58/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9956 - loss: 0.0116 - val_accuracy: 0.7576 - val_loss: 2.0847\n",
      "Epoch 59/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9938 - loss: 0.0107 - val_accuracy: 0.7500 - val_loss: 2.1035\n",
      "Epoch 60/60\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9913 - loss: 0.0374 - val_accuracy: 0.6843 - val_loss: 1.9259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1be5905eab0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train , validation_data= validation  , epochs= 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save(\"Trained_Model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
